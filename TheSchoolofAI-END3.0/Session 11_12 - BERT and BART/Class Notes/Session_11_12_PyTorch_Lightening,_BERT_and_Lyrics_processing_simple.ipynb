{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Session 11/12 - PyTorch Lightening, BERT and_Lyrics processing-simple.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nishasathish13/TheSchoolofAI-END3.0/blob/main/TheSchoolofAI-END3.0/Session%2011_12%20-%20BERT%20and%20BART/Class%20Notes/Session_11_12_PyTorch_Lightening%2C_BERT_and_Lyrics_processing_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhHatAeaO7CM"
      },
      "source": [
        "# Data-prep for \"BART learns to rap\"\n",
        "\n",
        "This notebook prepares the data for the \"BART learns to rap\" model by loading the data taken from http://www.github.com/fpaupier/RapLyrics-Scraper\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zce2cIpbO7CN"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "import math\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cloning the git repo"
      ],
      "metadata": {
        "id": "dVxohVLb4bf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fpaupier/RapLyrics-Scraper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPHyp55E21ug",
        "outputId": "3a06157b-2f06-46dd-8904-52c57b291bb5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RapLyrics-Scraper'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 131 (delta 3), reused 4 (delta 1), pack-reused 121\u001b[K\n",
            "Receiving objects: 100% (131/131), 5.57 MiB | 13.05 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Or download the required lyrics folder"
      ],
      "metadata": {
        "id": "CKd6s-NT4d9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://github.com/fpaupier/RapLyrics-Scraper/tree/master/lyrics_US'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwdWLrwT3-6S",
        "outputId": "7d398077-6dc8-41be-e2be-9e09fb3ae2e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-25 17:14:17--  https://github.com/fpaupier/RapLyrics-Scraper/tree/master/lyrics_US\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘lyrics_US’\n",
            "\n",
            "lyrics_US               [ <=>                ] 224.72K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-02-25 17:14:17 (1.71 MB/s) - ‘lyrics_US’ saved [230118]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xwJku3iO7CS"
      },
      "source": [
        "lyrics_dir = '/content/RapLyrics-Scraper/lyrics_US'\n",
        "lyric_files = os.listdir(lyrics_dir)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMYIdXH3O7CW"
      },
      "source": [
        "with open(os.path.join(lyrics_dir, lyric_files[0]), 'r', encoding = 'utf-8') as f:\n",
        "    lyrics = f.read()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CED-DjGO7Ce"
      },
      "source": [
        "def create_lyric_pairs(lyrics):\n",
        "    ''' Function that creates pairs of lyrics\n",
        "        Args: lyrics - multiple songs by an artist in a text file\n",
        "        Returns: 2 lists - source and target sentences\n",
        "    '''\n",
        "    source = []\n",
        "    target = []\n",
        "    \n",
        "    \"\"\"\n",
        "    The re.sub() function is used to replace occurrences of a particular sub-string with another sub-string.\n",
        "    This function takes as input the following:\n",
        "\n",
        "    The sub-string to replace\n",
        "    The sub-string to replace with\n",
        "    The actual string\n",
        "    \"\"\"\n",
        "    lyrics_ = re.sub(r' \\([^)]*\\)', '', lyrics)\n",
        "    lyrics_ = lyrics_.replace('(Hook)', '')\n",
        "\n",
        "    lyrics_ = lyrics_.split('\\n')\n",
        "\n",
        "    # Clean up extra spaces in the lyrics\n",
        "    counter = 0\n",
        "    for i in range(len(lyrics_)-1):\n",
        "        if lyrics_[counter] == \"\" and lyrics[counter+1] == \"\":\n",
        "            lyrics_[counter+1].pop()\n",
        "        counter += 1\n",
        "    \n",
        "    counter = 0\n",
        "    for i in range(len(lyrics_)-1):\n",
        "        if lyrics_[counter] == \"\" and lyrics[counter+1] == \"\":\n",
        "            lyrics_[counter+1].pop()\n",
        "        counter += 1    \n",
        "    # replace a \"\" with the word break\n",
        "    for i in range(len(lyrics_)):\n",
        "        if lyrics_[i] == \"\":\n",
        "            lyrics_[i] = \"break\"\n",
        "    \n",
        "    counter = 0\n",
        "    for i in range(len(lyrics_) - 1):\n",
        "        if lyrics_[counter] != \"break\" and lyrics_[counter+1] != \"break\":\n",
        "            # Use one line and target is the next line\n",
        "            source.append(lyrics_[counter])\n",
        "            target.append(lyrics_[counter+1])\n",
        "            \n",
        "        counter += 1\n",
        "            \n",
        "    return source, target\n",
        "\n",
        "def noise_sentence(sentence_, percent_words, replacement_token = \"<mask>\"):\n",
        "    '''\n",
        "    Args: sentence - the sentence to noise\n",
        "          percent_words - the percent of words to remove\n",
        "    '''\n",
        "    # Create a list item and copy\n",
        "    sentence_ = sentence_.split(' ')\n",
        "    sentence = sentence_.copy()\n",
        "    \n",
        "    num_words = math.ceil(len(sentence) * percent_words)\n",
        "    \n",
        "    # Create an array of tokens to sample from; don't include the last word as an option because in the case of lyrics\n",
        "    # that word is often a rhyming word and plays an important role in song construction\n",
        "    sample_tokens = set(np.arange(0, np.maximum(1, len(sentence)-1)))\n",
        "    \n",
        "    words_to_noise = random.sample(sample_tokens, num_words)\n",
        "    \n",
        "    # Remove redundant spaces\n",
        "    sentence = re.sub(r' {2,5}', ' ', ' '.join(sentence))\n",
        "    \n",
        "    # Combine concurrent <mask> tokens into a single token; this just does two rounds of this; more could be done\n",
        "    sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n",
        "    sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n",
        "    return sentence\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D21tPjRQQbkW"
      },
      "source": [
        "# Noise the lyrics\n",
        "The process below noises the (source) lyric and creates the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0NZnuTIO7Ci"
      },
      "source": [
        "source_lyrics = []\n",
        "target_lyrics = []\n",
        "\n",
        "for i in range(len(lyric_files[1])):\n",
        "    with open(os.path.join(lyrics_dir, lyric_files[i]), 'r', encoding = 'utf-8') as f:\n",
        "        lyrics = f.read()\n",
        "        a, b = create_lyric_pairs(lyrics)\n",
        "        source_lyrics.extend(a)\n",
        "        target_lyrics.extend(b)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVpMhF6zO7Cm"
      },
      "source": [
        "# Set up the dataframe\n",
        "lyrics_df = pd.DataFrame({\"source\":source_lyrics, \"target\":target_lyrics})"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLIYB6j5O7Cq"
      },
      "source": [
        "# Remove duplicates; without this there's a lot of repetitiveness in the lyrics generated\n",
        "lyrics_df = lyrics_df.drop_duplicates(subset = 'source')\n",
        "lyrics_df = lyrics_df.drop_duplicates(subset = 'target')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5KvL-PSO7Cu"
      },
      "source": [
        "# Clean out the lyrics that contain a \":\"; this was specific to some lyrics and created some \n",
        "lyrics_df = lyrics_df[~lyrics_df.source.str.contains(\":\")]\n",
        "lyrics_df = lyrics_df[~lyrics_df.target.str.contains(\":\")]\n",
        "lyrics_df = lyrics_df[lyrics_df.target != \"break\"]\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nWuB0WgO7Cy"
      },
      "source": [
        "# Noise the source sentences\n",
        "lyrics_df['source'] = lyrics_df['source'].apply(lambda x: noise_sentence(x, 0.25))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN0VXk6dO7C5"
      },
      "source": [
        "lyrics_df.to_csv(\"lyrics_simple_noised.csv\", index = False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyrics_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ccWu6V6B5vTo",
        "outputId": "d77f6dd0-88a8-43f4-81dd-1eca4a634c33"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-02b89f7c-8b6e-4987-9cec-4926373c56b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Do you still believe in love?</td>\n",
              "      <td>Or do you like drugs?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ran into a night owl rollin' White Owls</td>\n",
              "      <td>Girl it's been awhile since I hit a White Owl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Girl it's been awhile since I hit a White Owl</td>\n",
              "      <td>I'm with it though, she a centerfold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I'm with it though, she a centerfold</td>\n",
              "      <td>Big ol' blunt look like tentacles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Big ol' blunt look like tentacles</td>\n",
              "      <td>She strip in Europe, Interpol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148411</th>\n",
              "      <td>Or get this shit right, check it, it's the B-I...</td>\n",
              "      <td>Ya'll niggas can't see Poppa, nor the Big Moma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148412</th>\n",
              "      <td>Ya'll niggas can't see Poppa, nor the Big Moma</td>\n",
              "      <td>Who you love... for the Y2G, the two ten</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148413</th>\n",
              "      <td>Who you love... for the Y2G, the two ten</td>\n",
              "      <td>We got it sewn, we don't need ya'll help, we h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148414</th>\n",
              "      <td>We got it sewn, we don't need ya'll help, we h...</td>\n",
              "      <td>Cause this goes out to cats not tryin to give ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148415</th>\n",
              "      <td>Cause this goes out to cats not tryin to give ...</td>\n",
              "      <td>BIG lives in us, shout him out...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>112173 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02b89f7c-8b6e-4987-9cec-4926373c56b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02b89f7c-8b6e-4987-9cec-4926373c56b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02b89f7c-8b6e-4987-9cec-4926373c56b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   source                                             target\n",
              "0                           Do you still believe in love?                              Or do you like drugs?\n",
              "1                 Ran into a night owl rollin' White Owls      Girl it's been awhile since I hit a White Owl\n",
              "2           Girl it's been awhile since I hit a White Owl               I'm with it though, she a centerfold\n",
              "3                    I'm with it though, she a centerfold                  Big ol' blunt look like tentacles\n",
              "4                       Big ol' blunt look like tentacles                      She strip in Europe, Interpol\n",
              "...                                                   ...                                                ...\n",
              "148411  Or get this shit right, check it, it's the B-I...     Ya'll niggas can't see Poppa, nor the Big Moma\n",
              "148412     Ya'll niggas can't see Poppa, nor the Big Moma           Who you love... for the Y2G, the two ten\n",
              "148413           Who you love... for the Y2G, the two ten  We got it sewn, we don't need ya'll help, we h...\n",
              "148414  We got it sewn, we don't need ya'll help, we h...  Cause this goes out to cats not tryin to give ...\n",
              "148415  Cause this goes out to cats not tryin to give ...                  BIG lives in us, shout him out...\n",
              "\n",
              "[112173 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpov0OyoO7C8",
        "outputId": "cc68d2d0-e2e2-4b7c-9d6d-d20016d5bc76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "# Out of interest take a look at the distribution of sentence lengths\n",
        "# It turns out there was something a bit funny going on here, but as the as the tokenizer limits the length of the sentences\n",
        "# fed to the model, it's not really an issue (aside from the document with training data possibly being a bit larger than it needs to be)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "length_of_sent = []\n",
        "for i in range(50000): #reducting the bounds\n",
        "    length_of_sent.append(len(lyrics_df.iloc[i, 1].split(' ')))\n",
        "    \n",
        "plt.hist(length_of_sent)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4.9917e+04, 5.3000e+01, 1.5000e+01, 9.0000e+00, 2.0000e+00,\n",
              "        0.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00]),\n",
              " array([  1. ,  43.6,  86.2, 128.8, 171.4, 214. , 256.6, 299.2, 341.8,\n",
              "        384.4, 427. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYddVv2NO7DA",
        "outputId": "2825c20f-1a2f-48db-b748-34cb398c43a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# For reference, the longest sentence 400 sentences from the end of the list was only 31 tokens long\n",
        "#16 in our case, because of lower bounds\n",
        "length_of_sent.sort()\n",
        "length_of_sent[-400]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zSjw7yGD5_2F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}