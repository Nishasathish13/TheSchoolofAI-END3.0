{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END2 Session 4_RNN_to_LSTM.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nishasathish13/TheSchoolofAI-END3.0/blob/main/Session%204%20-%20RNN%20are%20dead%2C%20and%20HandsOn/Assignment-part1/END2_Session_4_RNN_to_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SPhj6gnAnT2"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "#Using spacy Tokenizer\n",
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwn4oStE6PzV",
        "outputId": "efadb9ce-a73d-448a-8d93-47ad11b615cd"
      },
      "source": [
        "from torchtext.legacy import datasets\n",
        "\n",
        "#Downloadingg the IMDB dataset\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:02<00:00, 29.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DLJ86m56Xdn",
        "outputId": "14c0ae84-d6f6-4cf1-c5c7-7bcd44d08620"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXTWwqXA6rP2",
        "outputId": "a95095d3-8bba-4b26-9b29-dac3f38f8517"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['Two', 'dysfunctional', 'brothers', '(', 'Philip', 'Seymour', 'Hoffman', 'and', 'Ethan', 'Hawke', ')', 'get', 'tired', 'of', 'competing', 'for', 'who', 'is', 'the', 'bigger', 'f***-up', 'and', 'who', 'Daddy', '(', 'Albert', 'Finney', ')', 'loves', 'more', ',', 'so', 'they', 'hatch', 'a', 'hair', '-', 'brained', 'scheme', 'to', 'rob', 'Mommy', 'and', 'Daddy', \"'s\", 'jewelry', 'store', 'so', 'that', 'they', 'can', 'clear', 'their', 'debts', 'and', 'start', 'fresh', '.', 'Sounds', 'like', 'a', 'great', 'plan', 'except', 'that', 'this', 'is', 'a', 'suspenseful', '1970', \"'s\", 'style', 'melodrama', 'about', 'a', 'heist', 'gone', 'wrong', ',', 'and', 'boy', ',', 'do', 'things', 'really', 'go', 'wrong', 'here', 'for', 'our', 'hapless', 'duo', 'and', 'everyone', 'involved', '.', 'Lasciviously', 'concocted', 'by', 'screenwriter', 'Kelly', 'Masterson', 'and', 'classically', 'executed', 'by', 'director', 'Sidney', 'Lumet', ',', '\"', 'Before', 'the', 'Devil', 'Knows', 'You', \"'re\", 'Dead', '\"', 'uses', 'the', 'heist', 'as', 'its', 'McGuffin', 'to', 'delve', 'deep', 'into', 'family', 'drama.<br', '/><br', '/>Contrary', 'to', 'popular', 'belief', ',', 'Sidney', 'Lumet', 'is', 'not', 'dead', '.', 'At', 'age', '83', ',', 'he', 'has', 'apparently', 'made', 'a', 'deal', 'with', 'the', 'Devil', 'to', 'deliver', 'one', 'last', 'great', 'film', '.', 'Lumet', 'was', 'at', 'his', 'zenith', 'in', 'the', '1970', \"'s\", 'with', 'films', 'like', '\"', 'Dog', 'Day', 'Afternoon', ',', '\"', '\"', 'Serpico', ',', '\"', 'and', 'one', 'of', 'my', 'favorite', 'films', 'of', 'all', 'time', ',', '\"', 'Network', '\"', '.', 'He', 'has', 'somehow', 'managed', 'to', 'make', 'a', 'film', 'that', 'bears', 'all', 'the', 'hallmarks', 'of', 'his', 'classics', 'while', 'intertwining', 'some', 'more', 'modern', 'elements', '(', 'graphic', 'sexuality', ',', 'violence', ',', 'and', 'playing', 'with', 'time', '-', 'frames', 'and', 'POV', \"'s\", ')', 'into', 'a', 'crackling', ',', 'vibrant', ',', 'lean', ',', 'mean', ',', 'and', 'provocative', 'melodrama', '.', 'One', 'can', 'only', 'hope', 'that', 'some', 'of', 'the', 'modern', 'greats', '(', 'like', 'Scorsese', 'or', 'Spielberg', ')', 'who', 'emerged', 'during', 'the', 'same', 'decade', 'Lumet', 'was', 'at', 'the', 'top', 'of', 'his', 'game', 'will', 'have', 'this', 'much', 'chutzpah', 'left', 'when', 'they', 'reach', 'that', 'age.<br', '/><br', '/>Lumet', 'is', 'a', 'master', 'at', 'directing', 'people', 'walking', 'through', 'spaces', 'to', 'create', 'tension', 'and', 'develop', 'characters', '.', 'As', 'the', 'cast', 'waltzes', 'through', 'finely', 'appointed', 'Manhattan', 'offices', 'and', 'apartments', 'his', 'slowly', 'moving', 'camera', 'creates', 'a', 'palpable', 'sense', 'of', 'anxiety', 'as', 'we', 'never', 'know', 'who', 'might', 'be', 'around', 'the', 'next', 'corner', 'or', 'what', 'this', 'person', 'might', 'do', 'in', 'the', 'next', 'room', '.', 'Also', 'amazing', 'is', 'how', 'Lumet', 'utilizes', 'the', 'multiple', 'POV', 'and', 'shifting', 'time', '-', 'frame', 'approach', '.', 'The', 'coherent', 'and', 'classical', 'presentation', 'he', 'uses', 'makes', 'the', 'similarly', 'structured', 'films', 'of', 'wunderkinds', 'Christopher', 'Nolan', 'and', 'Alejandro', 'Gonzalez', 'Inarritu', 'seem', 'like', 'amateur', 'hour.<br', '/><br', '/>Of', 'course', ',', 'what', 'Lumet', 'is', 'best', 'at', 'is', 'directing', 'amazing', 'ensemble', 'casts', 'and', 'tricking', 'them', 'into', 'acting', 'within', 'an', 'inch', 'of', 'their', 'lives', '.', 'Philip', 'Seymour', 'Hoffman', 'has', 'never', 'been', ',', 'and', 'most', 'likely', 'never', 'will', 'be', ',', 'better', 'than', 'he', 'is', 'here', '.', 'Albert', 'Finney', \"'s\", 'quietly', 'searing', 'portrayal', 'of', 'a', 'father', 'betrayed', 'and', 'at', 'the', 'end', 'of', 'his', 'rope', 'is', 'a', 'masterpiece', 'to', 'watch', 'unfold', '.', 'Ethan', 'Hawke', ',', 'normally', 'a', 'nondescript', 'pretty', 'boy', ',', 'is', 'perfect', 'as', 'the', 'emotionally', 'crippled', 'younger', 'brother', 'who', 'has', 'skated', 'by', 'far', 'too', 'long', 'on', 'his', 'charms', 'and', 'looks', '.', 'The', 'coup', '-', 'de', '-', 'grace', ',', 'however', ',', 'is', 'the', 'series', 'of', 'scenes', 'between', 'Hoffman', 'and', 'Marisa', 'Tomei', ',', 'eerily', 'on', 'point', 'as', 'his', 'flighty', 'trophy', 'wife', '.', 'Lumet', 'runs', 'them', 'through', 'the', 'gamut', 'of', 'emotions', 'that', 'culminate', 'in', 'a', 'scene', 'that', 'is', 'the', 'best', 'of', 'its', 'kind', 'since', 'William', 'Holden', 'taunted', 'Beatrice', 'Straight', 'right', 'into', 'a', 'Best', 'Supporting', 'Actress', 'Oscar', 'in', '\"', 'Network', '.', '\"', '<', 'br', '/><br', '/>The', 'Devil', 'of', 'any', 'great', 'film', 'is', 'in', 'the', 'details', ',', 'from', 'Albert', 'Finney', \"'s\", 'tap', 'of', 'his', 'car', \"'s\", 'trunk', 'that', 'wo', \"n't\", 'close', 'due', 'to', 'a', 'fender', 'bender', ',', 'to', 'the', 'look', 'Amy', 'Ryan', '(', 'fresh', 'off', 'her', 'amazing', 'turn', 'in', '\"', 'Gone', 'Baby', 'Gone', '\"', ')', 'gives', 'her', 'ex', '-', 'husband', 'Ethan', 'Hawke', 'at', 'his', 'mawkish', 'promise', 'to', 'his', 'little', 'girl', 'all', 'three', 'of', 'them', 'knows', 'he', 'wo', \"n't\", 'keep', ',', 'to', 'the', 'systematic', 'unraveling', 'of', 'a', 'family', 'on', 'the', 'skids', ',', 'to', 'the', 'dialog', 'begging', 'for', 'cultists', 'to', 'quote', 'it', '(', 'my', 'favorite', 'line', 'being', 'the', 'hilariously', 'threatening', '\"', 'Do', 'you', 'mind', 'if', 'I', 'call', 'you', 'Chico', '?', '\"', ')', 'to', 'the', 'excellent', 'Carter', 'Burwell', 'score', '.', '\"', 'Before', 'the', 'Devil', 'Knows', 'You', \"'re\", 'Dead', '\"', 'is', 'the', 'film', 'of', 'the', 'year', '.', 'If', 'something', 'emerges', 'to', 'best', 'it', ',', 'then', 'we', 'know', 'a', 'few', 'other', 'deals', 'must', \"'ve\", 'been', 'brokered', 'with', 'Old', 'Scratch', '.'], 'label': 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HMVqiZd6tR0"
      },
      "source": [
        "import random\n",
        "\n",
        "#splitting into train and validation data\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOeQ6KpP7M-0",
        "outputId": "23b077af-7d87-4727-be5c-2ecdb761856a"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KixkM1jQ7TB-"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD4SFKnc7g0D",
        "outputId": "adcbfbd6-1710-48ba-ed3f-88af46e55f32"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttKvFTCQ7isK",
        "outputId": "46e1cc7f-e9a8-48d9-911e-4b02261971e8"
      },
      "source": [
        "#Top20 nmost frequent words\n",
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 202755), (',', 192304), ('.', 166205), ('and', 109267), ('a', 108951), ('of', 100755), ('to', 93415), ('is', 76409), ('in', 61231), ('I', 54331), ('it', 53702), ('that', 49281), ('\"', 44129), (\"'s\", 43421), ('this', 42424), ('-', 37156), ('/><br', 35492), ('was', 35161), ('as', 30491), ('with', 29823)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZXIsIV47mlI",
        "outputId": "f2e94ba2-9c95-4c7b-ceff-be22cb38fe40"
      },
      "source": [
        "#Returns List mapping indices to tokens.\n",
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmbx3T9-7x4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1d2492-8df2-4655-8eda-ad13f90d9c17"
      },
      "source": [
        "#Returns dictionary mapping tokens to indices\n",
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(None, {'neg': 0, 'pos': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3gBfP6mEJ_0"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4McNPlCZAun"
      },
      "source": [
        "##RNN CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2ZQQV1-ELZf"
      },
      "source": [
        "# import torch.nn as nn\n",
        "\n",
        "# class RNN(nn.Module):\n",
        "#     def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "#         super().__init__()\n",
        "        \n",
        "#         self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "#         self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        \n",
        "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "#     def forward(self, text):\n",
        "\n",
        "#         #text = [sent len, batch size]\n",
        "        \n",
        "#         embedded = self.embedding(text)\n",
        "        \n",
        "#         #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "#         output, hidden = self.rnn(embedded)\n",
        "        \n",
        "#         #output = [sent len, batch size, hid dim]\n",
        "#         #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "#         assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        \n",
        "#         return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOHfvgHbZEcZ"
      },
      "source": [
        "##LSTM CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZxJUbMZY95h"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        #Embedding layer\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "        #LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                            hidden_dim,\n",
        "                            batch_first=False)\n",
        "        \n",
        "        #Fullyconnected/Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        #print(\"text :\", text.shape)\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "        #print(\"embedded :\", embedded.shape)\n",
        "        # packed sequence, padding \n",
        "        # packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        #three outputs for LSTMs\n",
        "        packed_output, (hidden, cell) = self.encoder(embedded)\n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        #print(\"hidden :\", hidden.shape)\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        #print(\"dense_outputs :\", dense_outputs.shape)\n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "        #print(\"output :\", output.shape)    \n",
        "        return output\n",
        "        # return self.fc(hidden).squeeze(0)  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0_X5kSwENad"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = LSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdGb8dKBEO2x",
        "outputId": "78cd03be-bee9-4039-b0ab-28189d6d0e73"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "#28.5 million trainable parameters"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 2,867,049 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAeEtXiJEQCj"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Utp4-qAERRG"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyAXf58FESdL"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4yNiGXQETh9"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1iGJW1wEUrL"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # print(batch.text.squeeze().shape)\n",
        "        # print(batch.text.shape)\n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(batch.text).squeeze()\n",
        "        #print(predictions)\n",
        "        #print(predictions.shape, batch.label.shape)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "    \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNQxQS3tEWUW"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVM8MtV6EYIw"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ5KZmM4EZXW",
        "outputId": "e45fe72f-40ae-4d9f-d41b-6c02f9f6ead7"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 19m 35s\n",
            "\tTrain Loss: 0.817 | Train Acc: 49.62%\n",
            "\t Val. Loss: 0.806 |  Val. Acc: 50.74%\n",
            "Epoch: 02 | Epoch Time: 21m 51s\n",
            "\tTrain Loss: 0.816 | Train Acc: 49.68%\n",
            "\t Val. Loss: 0.806 |  Val. Acc: 50.74%\n",
            "Epoch: 03 | Epoch Time: 22m 26s\n",
            "\tTrain Loss: 0.816 | Train Acc: 49.68%\n",
            "\t Val. Loss: 0.806 |  Val. Acc: 50.74%\n",
            "Epoch: 04 | Epoch Time: 20m 0s\n",
            "\tTrain Loss: 0.817 | Train Acc: 49.65%\n",
            "\t Val. Loss: 0.806 |  Val. Acc: 50.74%\n",
            "Epoch: 05 | Epoch Time: 19m 34s\n",
            "\tTrain Loss: 0.817 | Train Acc: 49.67%\n",
            "\t Val. Loss: 0.806 |  Val. Acc: 50.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIiKAJMaEbKO",
        "outputId": "df4153c8-0a0e-418a-e668-5d777a2202a0"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.813 | Test Acc: 50.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G024NssCEcj0"
      },
      "source": [
        "#Results from RNN Model\n",
        "\n",
        "# Epoch: 01 | Epoch Time: 10m 45s\n",
        "# \tTrain Loss: 0.694 | Train Acc: 49.16%\n",
        "# \t Val. Loss: 0.696 |  Val. Acc: 50.36%\n",
        "# Epoch: 02 | Epoch Time: 10m 40s\n",
        "# \tTrain Loss: 0.693 | Train Acc: 50.31%\n",
        "# \t Val. Loss: 0.695 |  Val. Acc: 49.04%\n",
        "# Epoch: 03 | Epoch Time: 10m 39s\n",
        "# \tTrain Loss: 0.693 | Train Acc: 50.50%\n",
        "# \t Val. Loss: 0.696 |  Val. Acc: 50.02%\n",
        "# Epoch: 04 | Epoch Time: 10m 43s\n",
        "# \tTrain Loss: 0.693 | Train Acc: 50.63%\n",
        "# \t Val. Loss: 0.696 |  Val. Acc: 50.15%\n",
        "# Epoch: 05 | Epoch Time: 10m 38s\n",
        "# \tTrain Loss: 0.693 | Train Acc: 50.37%\n",
        "# \t Val. Loss: 0.695 |  Val. Acc: 49.17%\n",
        "\n",
        "# Test Loss: 0.706 | Test Acc: 47.98%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvUDLN1DxRQb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}