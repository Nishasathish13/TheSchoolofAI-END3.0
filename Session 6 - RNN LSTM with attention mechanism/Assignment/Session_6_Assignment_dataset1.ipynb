{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 6_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nishasathish13/TheSchoolofAI-END3.0/blob/main/Session%206%20-%20RNN%20LSTM%20with%20attention%20mechanism/Assignment/Session_6_Assignment_dataset1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJK_W26qutG2"
      },
      "source": [
        "#Bulding up of code from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDG7AwmXuxGa"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#!wget https://download.pytorch.org/tutorial/data.zip\n",
        "#!unzip data.zip"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7lX9Fygfryx"
      },
      "source": [
        "#for tarfile\n",
        "\n",
        "import tarfile\n",
        "filename = \"/content/Question_Answer_Dataset_v1.2.tar.gz\"\n",
        "tf = tarfile.open(filename)\n",
        "print(tf.getnames())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HOoxPmxhh5m"
      },
      "source": [
        "tf.extractall('/content/tmp') #extract the files to a folder"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAeTnRDIDzoV"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "#writing a class which can ingest the data and give us output\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {} #to store the mapping of word to index\n",
        "        self.word2count = {} #to store the count of the words\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"} #adding our SOS and EOS index\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '): #read a sentence, split the words by space and pass the words to the addWord function\n",
        "            self.addWord(word) #addWord function which takes the words as input, defined after this line\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index: #we need to make a set of all the words, hence reading it only if it is not already present in word2index\n",
        "            self.word2index[word] = self.n_words #add the key (word) and the value(n_words) pair to word2index\n",
        "            self.word2count[word] = 1 #1st time seeing the word, hence 1\n",
        "            self.index2word[self.n_words] = word #updating our index2word\n",
        "            self.n_words += 1 #increasing the count by 1 for the next word, to allot unique index\n",
        "        else:\n",
        "            self.word2count[word] += 1 #if we have not seen the word, just increasing the particular sequence\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "#normalising of sentences\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s) #import re library\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('/content/question_answer_pairs.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # import codecs\n",
        "    # with codecs.open('/content/tmp/Question_Answer_Dataset_v1.2/S08/question_answer_pairs.txt', \"r\", \"utf-8\") as test_file:\n",
        "    # lines = test_file.read().strip().split('\\n')\n",
        "\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')[1:-3]] for l in lines] #normalizing word by word available for us in each line\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    \"\"\"\n",
        "    why do we need reverse, it is a googles invention,\n",
        "    it was found that sometimes the model learns better if trained using the reversed sentences\n",
        "    especially true for indo european languages\n",
        "    \"\"\"\n",
        "    if reverse: #applies only if reverse is true\n",
        "      pairs = [list(reversed(p)) for p in pairs]\n",
        "      input_lang = Lang(lang2)\n",
        "      output_lang = Lang(lang1)\n",
        "    else: #if reverse is False\n",
        "      input_lang = Lang(lang1)\n",
        "      output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "#utility functions\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'eng', True)\n",
        "    print(random.choice(pairs))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLmMxNbAu_Fr"
      },
      "source": [
        "#exploring the dataset and its behavior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW1XbLvdv65f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e85363-9b76-4dd0-c110-8531b3fc57f7"
      },
      "source": [
        "lines = open('/content/question_answer_pairs.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "lines[0:4]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ArticleTitle\\tQuestion\\tAnswer\\tDifficultyFromQuestioner\\tDifficultyFromAnswerer\\tArticleFile',\n",
              " 'Alessandro_Volta\\tWas Volta an Italian physicist?\\tyes\\teasy\\teasy\\tdata/set4/a10',\n",
              " 'Alessandro_Volta\\tWas Volta an Italian physicist?\\tyes\\teasy\\teasy\\tdata/set4/a10',\n",
              " 'Alessandro_Volta\\tIs Volta buried in the city of Pittsburgh?\\tno\\teasy\\teasy\\tdata/set4/a10']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV1FcZ5gTK-v"
      },
      "source": [
        "pairs = [[normalizeString(s) for s in l.split('\\t')[1:-3]] for l in lines]\n",
        "pairs[0:4]\n",
        "type(pairs)\n",
        "for p in pairs:\n",
        "  print(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY_Qt9qwT7Yq"
      },
      "source": [
        "for names in "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "Fwx9P2tuUDLS",
        "outputId": "58a9ee27-88f3-4f05-93d4-11a7922d8a90"
      },
      "source": [
        "nis"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-c4dd1cd50359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'nis' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htslTvQ9TWeU"
      },
      "source": [
        "if reverse: #applies only if reverse is true\n",
        "    pairs = [list(reversed(p)) for p in pairs]\n",
        "    input_lang = Lang(lang2)\n",
        "    output_lang = Lang(lang1)\n",
        "else: #if reverse is False\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "\n",
        "return input_lang, output_lang, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Drm-08CxHMoU",
        "outputId": "0c3b63d4-9f6b-4f8d-85bb-00ea74d2997a"
      },
      "source": [
        "len(lines)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQRreqKy6kGE",
        "outputId": "d53251a3-5383-4608-f707-e6b25760994e"
      },
      "source": [
        "len(pairs)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "826"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aspm0zAV4bwm"
      },
      "source": [
        "for p in pairs:\n",
        "  print(p[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1cjBvto4vLL"
      },
      "source": [
        "d = p[0].split(' ')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x874oAQ7tJ5",
        "outputId": "477c8f81-bd2c-40a7-b504-a94b70f389db"
      },
      "source": [
        "d"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['did', 'vibraphones', 'exist', 'in', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GVZzv8KxfOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44432513-d98b-4bb3-8701-91b879367b73"
      },
      "source": [
        "x = [[s for s in l.split('\\t')] for l in lines]\n",
        "x[0:4]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ArticleTitle',\n",
              "  'Question',\n",
              "  'Answer',\n",
              "  'DifficultyFromQuestioner',\n",
              "  'DifficultyFromAnswerer',\n",
              "  'ArticleFile'],\n",
              " ['Alessandro_Volta',\n",
              "  'Was Volta an Italian physicist?',\n",
              "  'yes',\n",
              "  'easy',\n",
              "  'easy',\n",
              "  'data/set4/a10'],\n",
              " ['Alessandro_Volta',\n",
              "  'Was Volta an Italian physicist?',\n",
              "  'yes',\n",
              "  'easy',\n",
              "  'easy',\n",
              "  'data/set4/a10'],\n",
              " ['Alessandro_Volta',\n",
              "  'Is Volta buried in the city of Pittsburgh?',\n",
              "  'no',\n",
              "  'easy',\n",
              "  'easy',\n",
              "  'data/set4/a10']]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V33IhdOx0hr",
        "outputId": "ec0981a6-d37f-46b7-db20-65da8e05f7b9"
      },
      "source": [
        "x = [[s for s in l.split('\\t')[1:-3]] for l in lines]\n",
        "x[0]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Question', 'Answer']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1FaOAEOHyUk",
        "outputId": "a64a9b47-7eff-4e04-e343-9608796f5b94"
      },
      "source": [
        "type(pairs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89oBpJAcIF0N",
        "outputId": "342ca98f-469d-4bb6-e8c6-b2ee414a6b75"
      },
      "source": [
        "pairs[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['j ai ans .', 'i m .'],\n",
              " ['je vais bien .', 'i m ok .'],\n",
              " ['ca va .', 'i m ok .'],\n",
              " ['je suis gras .', 'i m fat .'],\n",
              " ['je suis gros .', 'i m fat .']]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwsY5FiIIK7A"
      },
      "source": [
        "# The architecture we are building\n",
        "\n",
        "![image](https://miro.medium.com/max/1838/1*tXchCn0hBSUau3WO0ViD7w.jpeg)\n",
        "\n",
        "As we can see here, we will have an encoder, an attention mechanism block and decoder. In the final code the attention mechanicm block and decoder will be merged into single block as we need both to work together. \n",
        "\n",
        "As we can see here, we need to create a copy of h1, h2, h3 and h4. These are encoder outputs for a sentence with 4 words. \n",
        "\n",
        "# Encoder\n",
        "\n",
        "We will build our encoder with a GRU, but that's all we know. Let's NOT strait away build a class, but see how to come up with one for the Encoder. We need to answer few questions first:\n",
        "1. what would be the hidden size of our GRU\n",
        "2. What would be the input size\n",
        "3. What would be the embedding dimesions. \n",
        "\n",
        "For simplicity, lets keep 1. and 3. to be 256. \n",
        "\n",
        "We can't feed our input directly to GRU, we need to tensorize it, convert to embeddings first. \n",
        "\n",
        "`embedding = nn.Embedding(input_size, hidden_size) `\n",
        "\n",
        "## What is input_size?\n",
        "\n",
        "Remember the line below?\n",
        "\n",
        "`input_lang, output_lang, pairs = prepareData('eng', 'fra', True)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY5ZRwOkIHiR",
        "outputId": "a3822374-ee72-4367-ce75-dc86b528c3c5"
      },
      "source": [
        "input_lang"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Lang at 0x7f58ba6cde50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCPsLCpTIRmz"
      },
      "source": [
        "help(input_lang)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzMp8NcFIUlC"
      },
      "source": [
        "input_lang.__dict__.items()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot9BcpB3IaZA",
        "outputId": "cdb567e6-462f-4e20-d421-42614f8d3c3f"
      },
      "source": [
        "input_size = input_lang.n_words\n",
        "hidden_size = 256\n",
        "input_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4345"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4R6wxC-Ipkw"
      },
      "source": [
        "embedding = nn.Embedding(input_size, hidden_size)\n",
        "gru = nn.GRU(hidden_size, hidden_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAMIb49kI_BL",
        "outputId": "7f3e3d1b-3dc7-42c0-8740-6e302955ce15"
      },
      "source": [
        "sample = random.choice(pairs)\n",
        "sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tu es contrarie .', 'you re upset .']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVu_qJlQK2mE",
        "outputId": "64f6fd13-4656-484c-a1d9-d9e6ce61cf05"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0znN6aYDeLv",
        "outputId": "9a06cc17-7b6b-4c84-996c-269e6aea2dc1"
      },
      "source": [
        "type(sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "CSc3SeyQJIAg",
        "outputId": "0d593bba-16ec-4623-99b5-1e9dfec2fe77"
      },
      "source": [
        "\"\"\"\n",
        "TypeError: embedding(): argument 'indices' (position 2) must be Tensor, not str\n",
        "as the samples have to converted into tensor, currently sample is a list\n",
        "\"\"\"\n",
        "embedding_input = embedding(sample[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e1a57333920c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mto\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0minto\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrently\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0membedding_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jds83uf2JOOm",
        "outputId": "3fb1b745-75a1-4af1-d71d-5af8cc6595be"
      },
      "source": [
        "#before converting ot Tensor, we need to tokenize them and apply the necessary normalizations\n",
        "sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tu es contrarie .', 'you re upset .']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_gMRQxjPEKYw",
        "outputId": "0f6f3dda-b004-492f-99b2-39ef29e7bd52"
      },
      "source": [
        "sample[0] #input sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tu es contrarie .'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PaXqkpZnEMWj",
        "outputId": "d48980af-53f2-4ed8-c730-4fabf2fc854e"
      },
      "source": [
        "sample[1] #output sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'you re upset .'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA6M3xhyJRJW",
        "outputId": "59480428-832e-4244-deb2-fb81e6b2576f"
      },
      "source": [
        "input_sentence = sample[0]\n",
        "output_sentence = sample[1]\n",
        "\n",
        "input_lang.word2index['est'] #index of the french word 'est' is 25"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E57BWJHJdoi"
      },
      "source": [
        "for word in input_sentence:\n",
        "  print(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcQKsPxqJhlu",
        "outputId": "f3c328c2-a9a8-4622-f3d6-f6b312fcbfa4"
      },
      "source": [
        "for word in input_sentence.split(' '):\n",
        "  print(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tu\n",
            "es\n",
            "contrarie\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjNfpJbYJmKg",
        "outputId": "10826275-f7f4-494c-f9bc-d1d8b86a78f3"
      },
      "source": [
        "input_indices = [input_lang.word2index[word] for word in input_sentence.split(' ')]\n",
        "#use ctrl+d to select the consecutive same words\n",
        "output_indices = [output_lang.word2index[word] for word in output_sentence.split(' ')]\n",
        "input_indices, output_indices\n",
        "#list of indices, still not a tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([210, 211, 609, 5], [129, 78, 329, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "h3QSMYwoJzr8",
        "outputId": "335bae2f-24b8-4a54-faa5-26b22dc6004d"
      },
      "source": [
        "embedding_input = embedding(input_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5eba33aec1af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzvgEf40J5a2"
      },
      "source": [
        "input_indices.append(EOS_token) #appending the EOS token\n",
        "output_indices.append(EOS_token) #appending the EOS token\n",
        "input_indices, output_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2DCu5CsKCWy"
      },
      "source": [
        "input_tensor = torch.tensor(input_indices, dtype=torch.long, device=device)\n",
        "output_tensor = torch.tensor(output_indices, dtype=torch.long, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwCukAHjKRqa",
        "outputId": "fa5fe720-31d0-4693-c03d-2f5222ffe460"
      },
      "source": [
        "input_tensor.shape, output_tensor.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4]), torch.Size([4]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxhmqv0rKV43"
      },
      "source": [
        "#the error is because we do not have all the tensors at one place either CPU or GPU (Cuda)\n",
        "embedding_input = embedding(input_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIOiEKUKLDbk"
      },
      "source": [
        "embedding = nn.Embedding(input_size, hidden_size).to(device) #moving embedding to cpu\n",
        "gru = nn.GRU(hidden_size, hidden_size).to(device) #moving embedding to cpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0pQVrIQLNA0",
        "outputId": "f34ae98a-09cf-4140-b79a-25ef4e824504"
      },
      "source": [
        "embedding_input = embedding(input_tensor)\n",
        "embedding_input.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWmACcb5LS1y",
        "outputId": "e7a42dfa-5c44-42c7-c4c2-5d28c64a7bbe"
      },
      "source": [
        "input_tensor #we should have the len of list that is displayed in the previous cell [8, 256], 8th token being for EOS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([210, 211, 609,   5])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOOjODorLgbJ",
        "outputId": "52a48333-caf7-4865-8685-12ac507085f9"
      },
      "source": [
        "#this step is done to add extra dimension, to fake a batch\n",
        "input_tensor.shape, input_tensor.view(-1, 1).shape #.view flattens/unsqueezes "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4]), torch.Size([4, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-7AV8GgLp-u",
        "outputId": "ae5656e4-d055-4214-aead-76cf31a93053"
      },
      "source": [
        "print(embedding_input.shape)\n",
        "embedding_input = embedding(input_tensor.view(-1, 1))\n",
        "print(embedding_input.shape) #incase of NLP the batch size is the 2nd input, whereas in CV usually it is the 1st!!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n",
            "torch.Size([4, 1, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS0iGCt2L2aa"
      },
      "source": [
        "# output, hidden = gru(embedde_input, ?)\n",
        "hidden = torch.zeros(1, 1, 256, device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvJDgd6tMgtL",
        "outputId": "84ef17c8-3979-48a4-86bd-311e9ef6956f"
      },
      "source": [
        "embedding_input = embedding(input_tensor.view(-1, 1))\n",
        "output, hidden = gru(embedding_input, hidden)\n",
        "\n",
        "#each word has 256 dimension\n",
        "output.shape, output[0, 0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 1, 256]), torch.Size([256]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "CgrsOjFxPoik",
        "outputId": "e98112e2-0143-4619-cda9-432e44e651ce"
      },
      "source": [
        "output[7,0].shape #cannot go beyour 7 as we  have only 8 words in our instance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-89ad93979573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;31m#cannot go beyour 7 as we  have only 8 words in our instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 7 is out of bounds for dimension 0 with size 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZAzkzkKNo_l",
        "outputId": "1ae972ab-60ef-4394-fec0-03c8ec44be02"
      },
      "source": [
        "encoder_outputs = torch.zeros(MAX_LENGTH, 256, device=device)\n",
        "encoder_outputs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozs4sykfOS8j",
        "outputId": "02a73fe5-9b0c-49c4-90f6-83327ba9511d"
      },
      "source": [
        "input_tensor.size()[0], input_tensor.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, torch.Size([4]))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZomwGYAbO0iz"
      },
      "source": [
        "encoder_outputs = torch.zeros(MAX_LENGTH, 256, device=device) #creating the fake output of len 10 as our max length is 10, all zeros\n",
        "hidden = torch.zeros(1, 1, 256, device = device)\n",
        "\n",
        "for i in range(input_tensor.size()[0]): #we want to send the words one by one, to have the hidden layer for each word which inturn is one of the input for the next word.\n",
        "  embedding_input = embedding(input_tensor[i].view(-1, 1))\n",
        "  output, hidden = gru(embedding_input, hidden)\n",
        "  encoder_outputs[i] += output[0, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szh9dWLdPBII",
        "outputId": "938d5bc2-3762-420e-acc1-4b4b92f2d45c"
      },
      "source": [
        "encoder_outputs.shape, hidden.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 256]), torch.Size([1, 1, 256]))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqgndIpsQAjz",
        "outputId": "132f33fa-2e74-4c46-ca51-a085623e8e8b"
      },
      "source": [
        "encoder_outputs[0:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0331,  0.0143, -0.2156,  ...,  0.4149, -0.0311, -0.2988],\n",
              "        [ 0.4259, -0.0466, -0.1860,  ..., -0.0905, -0.2889, -0.5617],\n",
              "        [ 0.3952,  0.1580, -0.0544,  ..., -0.3181, -0.4257, -0.5128],\n",
              "        [ 0.1975, -0.0589, -0.1521,  ...,  0.0705, -0.1617, -0.5669]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umC9gtYpQCJ3"
      },
      "source": [
        "encoder_outputs[7:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XswFsPSXQWzy"
      },
      "source": [
        "# 😁\n",
        "\n",
        "Finally our Encoder is fully ready. Now let's look at the class we wrote in the last class to see what we missed!\n",
        "\n",
        "```\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "```\n",
        "\n",
        "Cool! Next let's build out Decoder where we have attention in-built.\n",
        "\n",
        "# Decoder with Attention\n",
        "\n",
        "Here is the plan. \n",
        "\n",
        "1. First input to the decoder will be SOS_token, later inputs would be the words it predicted (unless we implement teacher forcing)\n",
        "2. decoder/GRU's hidden state will be initialized with the encoder's last hidden state\n",
        "3. we will use gru's hidden state and last prediction to generate attention weight using a FC layer. \n",
        "4. this attention weight will be used to weigh the encoder_outputs using batch matric multiplication. This will give us a NEW view on how to look at encoder_states.\n",
        "5. this attention applied encoder_states will then be concatenated with the input, and then sent a linear layer and _then_ sent to the GRU. \n",
        "6. GRU's output will be sent to a FC layer to predict one of the output_language words\n",
        "\n",
        "Let's prepare all the inputs we need to do this\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMeO4AyyvlW8"
      },
      "source": [
        "#building the code from scartch Part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gQIvExHQKN1"
      },
      "source": [
        "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "decoder_hidden = hidden\n",
        "decoded_words = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2MKIEpYQnn_",
        "outputId": "a10aeb38-6045-4cfe-ce6f-72c28c422c88"
      },
      "source": [
        "# decoder s0\n",
        "\n",
        "#output size will be equal to the vocab size of the output language (english in this case)\n",
        "output_size = output_lang.n_words\n",
        "embedding = nn.Embedding(output_size, 256).to(device) \n",
        "embedded = embedding(decoder_input) #the first word is SOS\n",
        "embedded.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D8GxzPXQygF"
      },
      "source": [
        "# 256 * 2 >> after concatenation , concatenation of S0 and h1\n",
        "attn_weight_layer = nn.Linear(256 * 2, 10).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjEjHiWmR10f",
        "outputId": "812c8bff-8483-4046-c7e8-0dd0ac0cf0dd"
      },
      "source": [
        "embedded.shape, decoder_hidden.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 256]), torch.Size([1, 1, 256]))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhNCOx5Zg27G",
        "outputId": "51b76db7-6a86-4fe2-8326-ccd1fe062acb"
      },
      "source": [
        "embedded[0].shape, decoder_hidden[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 256]), torch.Size([1, 256]))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTMhiykNR5H6",
        "outputId": "7817c35e-4b58-4ae9-978a-0edcbd237b11"
      },
      "source": [
        "torch.cat((embedded[0], decoder_hidden[0]), 1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_-gpdX6SHjd",
        "outputId": "2e293dfc-4393-4552-c655-51e416978269"
      },
      "source": [
        "attn_weight_layer = nn.Linear(256 * 2, 10).to(device) \n",
        "attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "attn_weights #expecting 10 outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0477,  0.0591, -0.5925,  0.5556,  0.0130,  0.4086, -0.2886,  0.0086,\n",
              "         -0.2965,  0.6957]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp_OX0CBSjo1",
        "outputId": "ff2ce732-e16a-44a3-f08d-304c2fb49863"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "attn_weight_layer = nn.Linear(256 * 2, 10).to(device)\n",
        "attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "attn_weights = F.softmax(attn_weights, dim = 1) #adding softmax in dim 1\n",
        "attn_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0634, 0.1228, 0.1235, 0.0725, 0.0638, 0.0993, 0.0830, 0.0949, 0.0741,\n",
              "         0.2027]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssRdVGK8m2J1"
      },
      "source": [
        "# import torch.nn.functional as F\n",
        "# attn_weight_layer = nn.Linear(256 * 2, 10).to(device)\n",
        "# attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "# attn_weights = F.softmax(attn_weights, dim = 0) #adding aoftmax in dim 0\n",
        "# attn_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXD9hbQXSme9"
      },
      "source": [
        "attn_weights.shape, encoder_outputs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVrmPmxgTL_c"
      },
      "source": [
        "#Performs a batch matrix-matrix product of matrices stored in input and mat2\n",
        "attn_applied = torch.bmm(attn_weights, encoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS_szUYNTnDF"
      },
      "source": [
        "attn_weights.unsqueeze(0).shape, encoder_outputs.unsqueeze(0).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guvc1vEyTvCb",
        "outputId": "0cca0334-4b61-4131-fca0-6ddb9e077411"
      },
      "source": [
        "attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "attn_applied.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b_2JHkmT_Uz"
      },
      "source": [
        "So, now we have this 256dm attn_applied encoder_outputs capturing what we should focus on on this step. We also have the input we already generated. That's 256dm again. GRU is gonna take 256 only. So we need to concatenate them, send to a linear layer to reduce dimensions, and then send to Gru\n",
        "![image](https://static.wikia.nocookie.net/mycun-the-movie/images/c/c2/Gru-icon.png/revision/latest/scale-to-width-down/250?cb=20151223171656)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oznlhn7tT1tt"
      },
      "source": [
        "input_to_gru_layer = nn.Linear(256 * 2, 256).to(device)\n",
        "embedded.shape, attn_applied.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x89whyZIUqBN"
      },
      "source": [
        "input_to_gru = input_to_gru_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "input_to_gru.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOWvOfQfUvpl"
      },
      "source": [
        "gru = nn.GRU(256, 256).to(device)\n",
        "decoder_hidden.shape, input_to_gru.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGCflmkaU3BT"
      },
      "source": [
        "input_to_gru = input_to_gru_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "input_to_gru = input_to_gru.unsqueeze(0)\n",
        "decoder_hidden.shape, input_to_gru.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK1qEzbwVDKR",
        "outputId": "25db972e-6733-4685-eccd-d40d852ab33e"
      },
      "source": [
        "output, decoder_hidden = gru(decoder_hidden, input_to_gru)\n",
        "output.shape, decoder_hidden.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 256]), torch.Size([1, 1, 256]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DNEbGsZVKB3"
      },
      "source": [
        "output_word_layer = nn.Linear(256, output_lang.n_words).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPGyQhGZVbUL"
      },
      "source": [
        "output = F.relu(output)\n",
        "output = F.softmax(output_word_layer(output[0]), dim=1)\n",
        "output.shape, output, output.data.topk(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iuhy4OMrVp6d"
      },
      "source": [
        "topv, topi = output.data.topk(1)\n",
        "output_lang.index2word[topi.item()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0Ganc48V7uN"
      },
      "source": [
        "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "decoder_hidden = hidden #decoder_hidden = encoder_hidden\n",
        "output_size = output_lang.n_words\n",
        "embedding = nn.Embedding(output_size, 256).to(device)\n",
        "embedded = embedding(decoder_input)\n",
        "attn_weight_layer = nn.Linear(256 * 2, 10).to(device)\n",
        "attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "attn_weights = F.softmax(attn_weights, dim = 1)\n",
        "attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "input_to_gru_layer = nn.Linear(256 * 2, 256).to(device)\n",
        "input_to_gru = input_to_gru_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "gru = nn.GRU(256, 256).to(device)\n",
        "input_to_gru = input_to_gru.unsqueeze(0)\n",
        "output, decoder_hidden = gru(input_to_gru, decoder_hidden)\n",
        "output_word_layer = nn.Linear(256, output_lang.n_words).to(device)\n",
        "output = F.relu(output)\n",
        "output = F.softmax(output_word_layer(output[0]), dim = 1)\n",
        "top_value, top_index = output.data.topk(1)\n",
        "output_lang.index2word[top_index.item()]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxTova29WjJG"
      },
      "source": [
        "embedding = nn.Embedding(output_size, 256).to(device)\n",
        "attn_weight_layer = nn.Linear(256 * 2, 10).to(device)\n",
        "input_to_gru_layer = nn.Linear(256 * 2, 256).to(device)\n",
        "gru = nn.GRU(256, 256).to(device)\n",
        "output_word_layer = nn.Linear(256, output_lang.n_words).to(device)\n",
        "\n",
        "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "decoder_hidden = hidden\n",
        "output_size = output_lang.n_words\n",
        "embedded = embedding(decoder_input)\n",
        "attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "attn_weights = F.softmax(attn_weights, dim = 1)\n",
        "attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "input_to_gru = input_to_gru_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "input_to_gru = input_to_gru.unsqueeze(0)\n",
        "output, decoder_hidden = gru(input_to_gru, decoder_hidden)\n",
        "output = F.relu(output)\n",
        "output = F.softmax(output_word_layer(output[0]), dim = 1)\n",
        "top_value, top_index = output.data.topk(1)\n",
        "output_lang.index2word[top_index.item()], attn_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNs6bXVvWvEp"
      },
      "source": [
        "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "decoder_hidden = hidden\n",
        "output_size = output_lang.n_words\n",
        "embedded = embedding(decoder_input)\n",
        "attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "attn_weights = F.softmax(attn_weights, dim = 1)\n",
        "attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "input_to_gru = input_to_gru_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "input_to_gru = input_to_gru.unsqueeze(0)\n",
        "output, decoder_hidden = gru(input_to_gru, decoder_hidden)\n",
        "output = F.relu(output)\n",
        "output = F.softmax(output_word_layer(output[0]), dim = 1)\n",
        "top_value, top_index = output.data.topk(1)\n",
        "output_lang.index2word[top_index.item()], attn_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZu1L1GCXIgs"
      },
      "source": [
        "decoder_input = torch.tensor([[top_index.item()]], device=device)\n",
        "decoder_hidden = hidden\n",
        "output_size = output_lang.n_words\n",
        "embedded = embedding(decoder_input)\n",
        "attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "attn_weights = F.softmax(attn_weights, dim = 1)\n",
        "attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "input_to_gru = input_to_gru_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "input_to_gru = input_to_gru.unsqueeze(0)\n",
        "output, decoder_hidden = gru(input_to_gru, decoder_hidden)\n",
        "output = F.relu(output)\n",
        "output = F.softmax(output_word_layer(output[0]), dim = 1)\n",
        "top_value, top_index = output.data.topk(1)\n",
        "output_lang.index2word[top_index.item()], attn_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZFrigonXdYp"
      },
      "source": [
        "decoder_input = torch.tensor([[top_index.item()]], device=device)\n",
        "decoder_hidden = hidden\n",
        "output_size = output_lang.n_words\n",
        "embedded = embedding(decoder_input)\n",
        "attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "attn_weights = F.softmax(attn_weights, dim = 1)\n",
        "attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "input_to_gru = input_to_gru_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "input_to_gru = input_to_gru.unsqueeze(0)\n",
        "output, decoder_hidden = gru(input_to_gru, decoder_hidden)\n",
        "output = F.relu(output)\n",
        "output = F.softmax(output_word_layer(output[0]), dim = 1)\n",
        "top_value, top_index = output.data.topk(1)\n",
        "output_lang.index2word[top_index.item()], attn_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5ep8CM-XfbH"
      },
      "source": [
        "for i in range(6):\n",
        "  decoder_input = torch.tensor([[output_indices[i]]], device=device)\n",
        "  decoder_hidden = hidden\n",
        "  output_size = output_lang.n_words\n",
        "  embedded = embedding(decoder_input)\n",
        "  attn_weights = attn_weight_layer(torch.cat((embedded[0], decoder_hidden[0]), 1))\n",
        "  attn_weights = F.softmax(attn_weights, dim = 1)\n",
        "  attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "  input_to_gru = input_to_gru_layer(torch.cat((embedded[0], attn_applied[0]), 1))\n",
        "  input_to_gru = input_to_gru.unsqueeze(0)\n",
        "  output, decoder_hidden = gru(input_to_gru, decoder_hidden)\n",
        "  output = F.relu(output)\n",
        "  output = F.softmax(output_word_layer(output[0]), dim = 1)\n",
        "  top_value, top_index = output.data.topk(1)\n",
        "  print(output_sentence.split(\" \")[i], output_indices[i], output_lang.index2word[top_index.item()], top_index.item() )\n",
        "  print(attn_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqyMLV6ZXivn"
      },
      "source": [
        "output_indices, output_sentence, input_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdDT4RrbYEZx"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_2OIu6iYKUt",
        "outputId": "264be95e-0e8d-44b0-ce26-4faacad36b33"
      },
      "source": [
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-to1tUHYLnx",
        "outputId": "b6dea4d0-f98c-4003-8f6b-24b9c7b9118d"
      },
      "source": [
        "# !wget https://download.pytorch.org/tutorial/data.zip\n",
        "\n",
        "# !unzip data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-02 13:44:12--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.226.52.90, 13.226.52.51, 13.226.52.128, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.226.52.90|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip.1’\n",
            "\n",
            "data.zip.1          100%[===================>]   2.75M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-12-02 13:44:12 (21.6 MB/s) - ‘data.zip.1’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  data.zip\n",
            "replace data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SMRS3vgvsrL"
      },
      "source": [
        "#exploring the dataset part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sUZeRVnj_09"
      },
      "source": [
        "lines = open('/content/question_answer_pairs.txt', encoding='utf-8').\\\n",
        "      read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "pairs = [[normalizeString(s) for s in l.split('?')] for l in lines]"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p0n59y_oSrH"
      },
      "source": [
        "lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlTU0EEfoZhD",
        "outputId": "b6c8cf7a-88ba-4f7f-face-4f79ed6c9c7c"
      },
      "source": [
        "len(l)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeYZOKISnSay"
      },
      "source": [
        "pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFP3iSJqlIkx",
        "outputId": "e00b3fc7-c9ee-4891-ec7f-8f0b199fc73e"
      },
      "source": [
        "for p in pairs:\n",
        "  print(' '.join(p[0].split()[2:]))\n",
        "  break"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "was volta an italian physicist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYJcwNwbqY7g",
        "outputId": "12d55609-3578-413c-a209-bebba966ba82"
      },
      "source": [
        "for p in pairs:\n",
        "  print(' '.join(p[1].split()[:-5]))\n",
        "  break"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_a83VbIrCAD"
      },
      "source": [
        "lines = open('/content/question_answer_pairs.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "line = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "# Split every line into pairs and normalize\n",
        "pairs = [l[1:-3] for l in line]\n",
        "# print(pairs)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZjfrFRrsnmg"
      },
      "source": [
        "for p in pairs:\n",
        "  print(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZpL0-I6rz0b",
        "outputId": "680136a1-3551-4229-f0a1-a842d1162021"
      },
      "source": [
        "len(p[0].split(' '))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "362I8kb_rONg"
      },
      "source": [
        "for l in line:\n",
        "  print((l)[1:-3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDSa4DeivyQR"
      },
      "source": [
        "#Actual code used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMKJsJ3GYH2m"
      },
      "source": [
        "%matplotlib inline\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TeplhycYMWv"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0inG08EYOKf"
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5os4B6QYPZ1"
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('/content/question_answer_pairs.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    line = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [l[1:-3] for l in line]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg2mGsUGYRI1"
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH\n",
        "        # and \\p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOYzEWwWYSfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcf25714-812b-4ef6-bc2e-7fedb1c5e762"
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'eng', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 825 sentence pairs\n",
            "Trimmed to 785 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 645\n",
            "eng 1323\n",
            "['yes', 'does the australian black swan have white feathers on its wings ?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq_rtqvzYTgG"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgKx-hHuYspE"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = F.relu(output)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wadJ6xpyZCF9"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyeUE5oaZG3d"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS8uKk2FZo44"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq0C4hNbZqIm"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uu4NaExZuJ9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8waPFLdZvf7"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud8lBnmqZwbl"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGPbkKkLZxtx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f16d49-df27-4245-cc9f-fb21414f5854"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2m 13s (- 31m 7s) (5000 6%) 3.9080\n",
            "4m 20s (- 28m 14s) (10000 13%) 3.2216\n",
            "6m 28s (- 25m 53s) (15000 20%) 2.7151\n",
            "8m 37s (- 23m 43s) (20000 26%) 2.2762\n",
            "10m 47s (- 21m 35s) (25000 33%) 2.0558\n",
            "12m 58s (- 19m 27s) (30000 40%) 1.8753\n",
            "15m 6s (- 17m 15s) (35000 46%) 1.8633\n",
            "17m 13s (- 15m 4s) (40000 53%) 1.8337\n",
            "19m 22s (- 12m 55s) (45000 60%) 1.8003\n",
            "21m 31s (- 10m 45s) (50000 66%) 1.8303\n",
            "23m 40s (- 8m 36s) (55000 73%) 1.9113\n",
            "25m 51s (- 6m 27s) (60000 80%) 2.1724\n",
            "27m 53s (- 4m 17s) (65000 86%) 3.5149\n",
            "29m 49s (- 2m 7s) (70000 93%) 3.9681\n",
            "31m 45s (- 0m 0s) (75000 100%) 3.8887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ipQPS5LZy-v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}